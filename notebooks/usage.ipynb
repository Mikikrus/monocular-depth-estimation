{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "import torchmetrics\n",
    "from lightning.pytorch import Trainer, callbacks, seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from src import DEVICE\n",
    "from src.data.data_module import DepthEstimationDataModule\n",
    "from src.models import Unet3Plus\n",
    "from src.train import losses\n",
    "from src.train import (\n",
    "    LightningModel,\n",
    "    ModelCheckpoint,\n",
    "    VisualizePrediction,\n",
    "    get_lr_scheduler_kwargs,\n",
    "    transforms,\n",
    ")\n",
    "from src.utils import download_dataset\n",
    "\n",
    "seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "src.train.losses.L1Loss"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_dir = \"../data\"\n",
    "    batch_size: int = 1\n",
    "    num_workers: int = os.cpu_count()\n",
    "    encoder_name: str = \"tf_efficientnetv2_m.in21k_ft_in1k\"\n",
    "    decoder_attention_type: str = \"scse\"\n",
    "    head_activation_name: str = \"sigmoid\"\n",
    "    optimizer: str = \"Adam\"\n",
    "    learning_rate: float = 1e-4\n",
    "    accumulate_grad_batches: int = 1\n",
    "    loss_function_name: str = \"L1Loss\"\n",
    "    wandb_project_name: str = \"depth-estimation\"\n",
    "config = Config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "download_dataset(destination_path=config.data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config.data_dir = os.path.join(config.data_dir,\"data\") #TODO fix zip file in gdrive"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr_scheduler_kwargs = get_lr_scheduler_kwargs(\n",
    "    data_dir=os.path.join(config.data_dir, \"train\", \"image\"),\n",
    "    batch_size=config.batch_size,\n",
    "    accumulate_grad_batches=config.accumulate_grad_batches,\n",
    ")\n",
    "data_module = DepthEstimationDataModule(\n",
    "    data_dir=config.data_dir, batch_size=config.batch_size, num_workers=config.num_workers, transforms=transforms\n",
    ")\n",
    "data_module.setup()\n",
    "model = Unet3Plus(\n",
    "    encoder_name=config.encoder_name,\n",
    "    classes=1,\n",
    "    activation=config.head_activation_name,\n",
    "    decoder_attention_type=config.decoder_attention_type,\n",
    ")\n",
    "lightning_model = LightningModel(\n",
    "    model=model,\n",
    "    optimizer=config.optimizer,\n",
    "    learning_rate=config.learning_rate,\n",
    "    loss=getattr(losses,config.loss_function_name)(ignore_values=0, reduction=\"sum\"),\n",
    "    lr_scheduler_params=lr_scheduler_kwargs,\n",
    ")\n",
    "wandb_logger = WandbLogger(project=config.wandb_project_name, config=asdict(config), reinit=True, log_model=\"all\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=2,\n",
    "    monitor=f\"Validation/{config.loss_function_name}\",\n",
    "    filename=\"{epoch:02d}-{Validation_\" + config.loss_function_name + \":.2f}\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator=DEVICE,\n",
    "    logger=wandb_logger,\n",
    "    max_epochs=1,\n",
    "    num_sanity_val_steps=1,\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=config.accumulate_grad_batches,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        VisualizePrediction()\n",
    "    ],\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.fit(lightning_model, data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}